{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "#import statistics as stats\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.preprocessing import MaxAbsScaler\n",
    "#from sklearn.preprocessing import RobustScaler\n",
    "#from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import cross_validate\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "#from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from deslib.static import Oracle\n",
    "import oracle # \n",
    "import sgh\n",
    "from rlo import * #rlo.py - Random Linear Oracle implementation based on Kuncheva's book. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.filterwarnings(action='once')\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's build a function to convert KEEL data to a regular CSV (remove annotations before data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keel2csv(file):\n",
    "    ''' Reads a KEEL .dat file, converts it into a regular CSV data file \n",
    "    that contains a header line. The output .csv file is written to the same \n",
    "    dir as the original .dat file. This function also returns a dict \n",
    "    {'numeric':[], 'nominal':[]} containg two lists, one for the numeric \n",
    "    attributes and the other for the nominal atributes.'''\n",
    "    filename = file.name\n",
    "    # Let's read the attribute types (useful for preprocessing) and also the \n",
    "    # column names from the @annotations, inclunding the target (class) column:\n",
    "    has_inputs = has_outputs = False\n",
    "    numeric_atts = []\n",
    "    nominal_atts = []\n",
    "    for line in file:\n",
    "        if '@attribute' in line:\n",
    "            if (' real' in line) or (' integer' in line):\n",
    "                numeric_atts.append(line.split(' ')[1])\n",
    "            elif '{' in line:\n",
    "                nominal_atts.append(line.split(' ')[1])\n",
    "        if line.startswith('@inputs'):\n",
    "            att_names = line[8:-1].replace(' ', '')\n",
    "            has_inputs = True\n",
    "        elif line.startswith('@input'):\n",
    "            att_names = line[7:-1].replace(' ', '')\n",
    "            has_inputs = True\n",
    "        elif line.startswith('@outputs') or line.startswith('@output'):\n",
    "            class_name = line[9:-1]\n",
    "            has_outputs = True\n",
    "            break\n",
    "        elif line.startswith('@output'):\n",
    "            class_name = line[8:-1]\n",
    "            has_outputs = True\n",
    "            break\n",
    "    if (not has_inputs) or (not has_outputs):\n",
    "        print('File ', filename, 'missing annotations?' )\n",
    "\n",
    "    columns = att_names + ',' + class_name\n",
    "\n",
    "    #Then, lets remove the annotations and save the column names and data into a csv file:\n",
    "    lines = file.readlines() \n",
    "    file.close()\n",
    "    new_file = open(filename[:-4]+'.csv','w')\n",
    "    new_file.write(columns+'\\n')\n",
    "    for line in lines:\n",
    "        if not line.startswith('@'):\n",
    "            new_file.write(line)\n",
    "    new_file.close()    \n",
    "    return {'numeric':numeric_atts, 'nominal':nominal_atts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we need to run through the files and execute the keel2csv function for each KEEL dat file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_names = ['ecoli3', 'segment0', 'vehicle2', 'yeast3','glass6']\n",
    "rootdir = '/Users/ailtonrodrigues/Desktop/Doctor CIN/data'\n",
    "# Link para os datasets: https://sci2s.ugr.es/keel/datasets.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting KEEL .dat files to CSV:\n",
    "att_types = {} #This dictionary will have each dataset name as key and will hold the attribute types.\n",
    "for name in ds_names:\n",
    "    for fold in range(1,6):\n",
    "        full_path = rootdir+'/'+name+'-5-fold/'+name+'-5-'+str(fold)+'tra.dat' \n",
    "        f = open(full_path, 'r')\n",
    "        att_types[name] = keel2csv(f)\n",
    "        f.close()\n",
    "        full_path = rootdir+'/'+name+'-5-fold/'+name+'-5-'+str(fold)+'tst.dat' \n",
    "        f = open(full_path, 'r')\n",
    "        keel2csv(f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok, now that we finally have all the data in CSV format, lets load them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create a dict structure such that I can access train fold 1 from \n",
    "# dataset wisconsin as datasets['wisconsin']['train'][0]\n",
    "\n",
    "datasets = {}\n",
    "for name in ds_names:\n",
    "    datasets[name] = {}\n",
    "    datasets[name]['train'] = []\n",
    "    datasets[name]['test'] = []\n",
    "    for fold in range(1,6):\n",
    "        csv_filename = rootdir+'/'+name+'-5-fold/'+name+'-5-'+str(fold)+'tra.csv'\n",
    "        df_train = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, error_bad_lines=False)\n",
    "        csv_filename = rootdir+'/'+name+'-5-fold/'+name+'-5-'+str(fold)+'tst.csv'\n",
    "        df_test = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, error_bad_lines=False)\n",
    "        datasets[name]['train'].append(df_train)\n",
    "        datasets[name]['test'].append(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Circularity</th>\n",
       "      <th>Distance_circularity</th>\n",
       "      <th>Radius_ratio</th>\n",
       "      <th>Praxis_aspect_ratio</th>\n",
       "      <th>Max_length_aspect_ratio</th>\n",
       "      <th>Scatter_ratio</th>\n",
       "      <th>Elongatedness</th>\n",
       "      <th>Praxis_rectangular</th>\n",
       "      <th>Length_rectangular</th>\n",
       "      <th>Major_variance</th>\n",
       "      <th>Minor_variance</th>\n",
       "      <th>Gyration_radius</th>\n",
       "      <th>Major_skewness</th>\n",
       "      <th>Minor_skewness</th>\n",
       "      <th>Minor_kurtosis</th>\n",
       "      <th>Major_kurtosis</th>\n",
       "      <th>Hollows_ratio</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>48</td>\n",
       "      <td>83</td>\n",
       "      <td>178</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>162</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>159</td>\n",
       "      <td>176</td>\n",
       "      <td>379</td>\n",
       "      <td>184</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>187</td>\n",
       "      <td>197</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>41</td>\n",
       "      <td>84</td>\n",
       "      <td>141</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>143</td>\n",
       "      <td>170</td>\n",
       "      <td>330</td>\n",
       "      <td>158</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>189</td>\n",
       "      <td>199</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>41</td>\n",
       "      <td>82</td>\n",
       "      <td>159</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>144</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>143</td>\n",
       "      <td>160</td>\n",
       "      <td>309</td>\n",
       "      <td>127</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>199</td>\n",
       "      <td>207</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>44</td>\n",
       "      <td>70</td>\n",
       "      <td>205</td>\n",
       "      <td>103</td>\n",
       "      <td>52</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>144</td>\n",
       "      <td>241</td>\n",
       "      <td>325</td>\n",
       "      <td>188</td>\n",
       "      <td>127</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>180</td>\n",
       "      <td>183</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>57</td>\n",
       "      <td>106</td>\n",
       "      <td>172</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>255</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>169</td>\n",
       "      <td>280</td>\n",
       "      <td>957</td>\n",
       "      <td>264</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>181</td>\n",
       "      <td>183</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "      <td>66</td>\n",
       "      <td>140</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>130</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>120</td>\n",
       "      <td>151</td>\n",
       "      <td>251</td>\n",
       "      <td>114</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>201</td>\n",
       "      <td>207</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>93</td>\n",
       "      <td>39</td>\n",
       "      <td>87</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>169</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>422</td>\n",
       "      <td>149</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>188</td>\n",
       "      <td>195</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>673</td>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>101</td>\n",
       "      <td>222</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>222</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>173</td>\n",
       "      <td>228</td>\n",
       "      <td>721</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>187</td>\n",
       "      <td>201</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>86</td>\n",
       "      <td>36</td>\n",
       "      <td>78</td>\n",
       "      <td>146</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>135</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>124</td>\n",
       "      <td>155</td>\n",
       "      <td>270</td>\n",
       "      <td>148</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>190</td>\n",
       "      <td>195</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>85</td>\n",
       "      <td>36</td>\n",
       "      <td>66</td>\n",
       "      <td>123</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>128</td>\n",
       "      <td>140</td>\n",
       "      <td>212</td>\n",
       "      <td>131</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>186</td>\n",
       "      <td>190</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Compactness  Circularity  Distance_circularity  Radius_ratio  \\\n",
       "0             95           48                    83           178   \n",
       "1             91           41                    84           141   \n",
       "2             93           41                    82           159   \n",
       "3             85           44                    70           205   \n",
       "4            107           57                   106           172   \n",
       "..           ...          ...                   ...           ...   \n",
       "671           93           34                    66           140   \n",
       "672           93           39                    87           183   \n",
       "673          106           54                   101           222   \n",
       "674           86           36                    78           146   \n",
       "675           85           36                    66           123   \n",
       "\n",
       "     Praxis_aspect_ratio  Max_length_aspect_ratio  Scatter_ratio  \\\n",
       "0                     72                       10            162   \n",
       "1                     57                        9            149   \n",
       "2                     63                        9            144   \n",
       "3                    103                       52            149   \n",
       "4                     50                        6            255   \n",
       "..                   ...                      ...            ...   \n",
       "671                   56                        7            130   \n",
       "672                   64                        8            169   \n",
       "673                   67                       12            222   \n",
       "674                   58                        7            135   \n",
       "675                   55                        5            120   \n",
       "\n",
       "     Elongatedness  Praxis_rectangular  Length_rectangular  Major_variance  \\\n",
       "0               42                  20                 159             176   \n",
       "1               45                  19                 143             170   \n",
       "2               46                  19                 143             160   \n",
       "3               45                  19                 144             241   \n",
       "4               26                  28                 169             280   \n",
       "..             ...                 ...                 ...             ...   \n",
       "671             51                  18                 120             151   \n",
       "672             40                  20                 134             200   \n",
       "673             30                  25                 173             228   \n",
       "674             50                  18                 124             155   \n",
       "675             56                  17                 128             140   \n",
       "\n",
       "     Minor_variance  Gyration_radius  Major_skewness  Minor_skewness  \\\n",
       "0               379              184              70               6   \n",
       "1               330              158              72               9   \n",
       "2               309              127              63               6   \n",
       "3               325              188             127               9   \n",
       "4               957              264              85               5   \n",
       "..              ...              ...             ...             ...   \n",
       "671             251              114              62               5   \n",
       "672             422              149              72               7   \n",
       "673             721              200              70               3   \n",
       "674             270              148              66               0   \n",
       "675             212              131              73               1   \n",
       "\n",
       "     Minor_kurtosis  Major_kurtosis  Hollows_ratio      Class  \n",
       "0                16             187            197   negative  \n",
       "1                14             189            199   negative  \n",
       "2                10             199            207   negative  \n",
       "3                11             180            183   positive  \n",
       "4                 9             181            183   positive  \n",
       "..              ...             ...            ...        ...  \n",
       "671              29             201            207   negative  \n",
       "672              25             188            195   negative  \n",
       "673               4             187            201   negative  \n",
       "674              25             190            195   negative  \n",
       "675              18             186            190   negative  \n",
       "\n",
       "[676 rows x 19 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['vehicle2']['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning (stripping) strings within dataframe and also changing class labels to 1 and 0.\n",
    "for name in ds_names:\n",
    "    for s in ['train', 'test']:\n",
    "        for fold in range(5):\n",
    "            df = datasets[name][s][fold]\n",
    "            df_obj = df.select_dtypes(['object'])\n",
    "            df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())\n",
    "            df['Class'] = df['Class'].replace(['positive', 'negative'],[1,0])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "Applying the Standard Scaler to the numeric attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "# for name in ds_names:\n",
    "#     for s in ['train', 'test']:\n",
    "#         for fold in range(5):\n",
    "#             datasets[name][s][fold][att_types[name]['numeric']] = ss.fit_transform(datasets[name][s][fold][att_types[name]['numeric']])\n",
    "\n",
    "for name in ds_names:\n",
    "    for fold in range(5):\n",
    "        datasets[name]['train'][fold][att_types[name]['numeric']] = ss.fit_transform(datasets[name]['train'][fold][att_types[name]['numeric']])\n",
    "        datasets[name]['test'][fold][att_types[name]['numeric']] = ss.transform(datasets[name]['test'][fold][att_types[name]['numeric']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "Here we must apply this encoding method to the nominal attributes in order to allow them to be managed by the classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ds_names:\n",
    "    for s in ['train', 'test']:\n",
    "        for fold in range(5):\n",
    "            for att in att_types[name]['nominal'][:-1]: #For each nominal attribute, except the target one (last one)\n",
    "                att_encoded = pd.get_dummies(datasets[name][s][fold][att], prefix = att)\n",
    "                datasets[name][s][fold] = datasets[name][s][fold].drop([att], axis = 1)\n",
    "                datasets[name][s][fold] = pd.concat([att_encoded, datasets[name][s][fold]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values\n",
    "\n",
    "Applying a Simple Imputer to the numeric attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "for name in ds_names:\n",
    "    for s in ['train', 'test']:\n",
    "        for fold in range(5):\n",
    "            datasets[name][s][fold][att_types[name]['numeric']] = imp_mean.fit_transform(datasets[name][s][fold][att_types[name]['numeric']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "\n",
    "1.\tSelecione \n",
    "    a.\tcinco bases de dados públicas (já com 5-folds extraídas da página:https://sci2s.ugr.es/keel/imbalanced.php ) com características diferentes.\n",
    "        ecoli3', 'segment0', 'vehicle2', 'yeast3','page-blocks0'\n",
    "        \n",
    "    \n",
    "    b. Para cada base calcule o Oracle no conjunto de teste para: \n",
    "        i.\tBagging\n",
    "        ii.\tAdaboost\n",
    "        iii.Random Subespace (50%)\n",
    "        iv.\tRandom Oracles\n",
    "\n",
    "    - Variando o número de classificadores-base {10, 20,...100}\n",
    "    - Use o perceptron como classificador-base e divida os fold usando 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulding and running the ensembles of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a results.csv file with a header row:\n",
    "results_file = open('./results.csv', 'a')\n",
    "header = 'Dataset Name,model,n_estimators,accuracy,acc_std_dev,f1,f1_std_dev,g_mean,g_mean_std_dev,oracle_mean,oracle_std_dev\\n'\n",
    "results_file.write(header)\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's run a single-model (perceptron) classifier to stablish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = open('./results.csv', 'a')\n",
    "\n",
    "model_percep = Perceptron(random_state=0)\n",
    "for name in ds_names:\n",
    "    acc_folds = []\n",
    "    f1_folds = []\n",
    "    g_mean_folds = []\n",
    "    for fold in range(5):\n",
    "        # Gather training data:\n",
    "        ds_train = datasets[name]['train'][fold]\n",
    "        target_att = ds_train.columns.tolist()[-1]\n",
    "        X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "        y_train = ds_train[target_att]\n",
    "\n",
    "        # Gather test data:\n",
    "        ds_test = datasets[name]['test'][fold]\n",
    "        X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "        y_test = ds_test[target_att]\n",
    "\n",
    "        # Train model with the training data, we need y_score for calculating ROC-AUC\n",
    "        y_score = model_percep.fit(X_train, y_train).decision_function(X_test)\n",
    "        \n",
    "        # Test model:\n",
    "        y_pred = model_percep.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "        g_mean = geometric_mean_score(y_test, y_pred)\n",
    "        \n",
    "        # Store metrics for this fold\n",
    "        acc_folds.append(acc)\n",
    "        f1_folds.append(f1)\n",
    "        g_mean_folds.append(g_mean)\n",
    "        \n",
    "        #cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        #print('Dataset %s, Fold %d, Accuracy: %.2f, F1-score: %.2f, ROC-AUC %.2f, G-Mean %.2f' % (name, fold, acc, f1, roc_auc, g_mean))\n",
    "        #print(cnf_matrix)\n",
    "    \n",
    "    # Calculate means and std devs for each metric \n",
    "    acc_mean = str(np.average(acc_folds))\n",
    "    acc_std_dev = str(np.std(acc_folds))\n",
    "    f1_mean = str(np.average(f1_folds))\n",
    "    f1_std_dev = str(np.std(f1_folds))\n",
    "    g_mean_mean = str(np.average(g_mean_folds))\n",
    "    g_mean_std_dev = str(np.std(g_mean_folds))\n",
    "    results_file.write(name+',Perceptron,1,'+acc_mean+','+acc_std_dev+','+f1_mean+','+f1_std_dev+','\n",
    "                       +g_mean_mean+','+g_mean_std_dev+', ,\\n')\n",
    "\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a generic function to run the ensembles with 5-fold cross val and save results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(meta_model_name, meta_model, results_file, save_models):\n",
    "    for n in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "        print('Running', meta_model_name, 'with %d base estimators'%n)\n",
    "        meta_model.n_estimators=n\n",
    "        for name in ds_names:\n",
    "            acc_folds = []\n",
    "            f1_folds = []\n",
    "            g_mean_folds = []\n",
    "            oracle_scores = []\n",
    "            for fold in range(5):\n",
    "                ## Gather training data:\n",
    "                ds_train = datasets[name]['train'][fold]\n",
    "                target_att = ds_train.columns.tolist()[-1]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "                y_train = ds_train[target_att]\n",
    "\n",
    "                ## Gather test data:\n",
    "                ds_test = datasets[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "                y_test = ds_test[target_att]\n",
    "\n",
    "                ## Train model with the training data:\n",
    "                meta_model.fit(X_train,y_train)\n",
    "                \n",
    "                ## Test model:\n",
    "                y_pred = meta_model.predict(X_test)\n",
    "                \n",
    "                if save_models:\n",
    "                    ## Save the model object to a file for later use\n",
    "                    filename = 'saved_models/'+meta_model_name+'_n'+str(n)+'_dataset_'+name+'_fold_'+str(fold)+'.sav'\n",
    "                    pickle.dump(meta_model, open(filename, 'wb'))\n",
    "                    ## Later load model with: loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "                ## Calculate metrics:\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "                g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "                ## Store metrics for this fold:\n",
    "                acc_folds.append(acc)\n",
    "                f1_folds.append(f1)\n",
    "                g_mean_folds.append(g_mean)\n",
    "                #cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                #print(cnf_matrix)\n",
    "\n",
    "                oracle = Oracle(meta_model).fit(X_train, y_train)\n",
    "                oracle_score = oracle.score(X_test, y_test)\n",
    "                oracle_scores.append(oracle_score)\n",
    "\n",
    "            ## Calculate means and std devs for each metric \n",
    "            acc_mean = str(np.average(acc_folds))\n",
    "            acc_std_dev = str(np.std(acc_folds))\n",
    "            f1_mean = str(np.average(f1_folds))\n",
    "            f1_std_dev = str(np.std(f1_folds))\n",
    "            g_mean_mean = str(np.average(g_mean_folds))\n",
    "            g_mean_std_dev = str(np.std(g_mean_folds))\n",
    "            oracle_mean = str(np.average(oracle_scores))\n",
    "            oracle_std_dev = str(np.std(oracle_scores))\n",
    "            results_file.write(name+','+meta_model_name+','+str(n)+','+acc_mean+','+acc_std_dev+','+f1_mean+','\n",
    "                               +f1_std_dev+','+g_mean_mean+','+g_mean_std_dev+','+oracle_mean+','+oracle_std_dev+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Bagging with 10 base estimators\n",
      "Running Bagging with 20 base estimators\n",
      "Running Bagging with 30 base estimators\n",
      "Running Bagging with 40 base estimators\n",
      "Running Bagging with 50 base estimators\n",
      "Running Bagging with 60 base estimators\n",
      "Running Bagging with 70 base estimators\n",
      "Running Bagging with 80 base estimators\n",
      "Running Bagging with 90 base estimators\n",
      "Running Bagging with 100 base estimators\n"
     ]
    }
   ],
   "source": [
    "results_file = open('./results.csv', 'a')\n",
    "\n",
    "#base_model = CalibratedClassifierCV(Perceptron(random_state=0))\n",
    "base_model = Perceptron(random_state=0)\n",
    "meta_model = BaggingClassifier(base_estimator=base_model, random_state=0, bootstrap=True,\n",
    "                                bootstrap_features=False, max_features=1.0, n_jobs=-1)            \n",
    "run_model('Bagging',meta_model, results_file, save_models=True)           \n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost with 10 base estimators\n",
      "Running AdaBoost with 20 base estimators\n",
      "Running AdaBoost with 30 base estimators\n",
      "Running AdaBoost with 40 base estimators\n",
      "Running AdaBoost with 50 base estimators\n",
      "Running AdaBoost with 60 base estimators\n",
      "Running AdaBoost with 70 base estimators\n",
      "Running AdaBoost with 80 base estimators\n",
      "Running AdaBoost with 90 base estimators\n",
      "Running AdaBoost with 100 base estimators\n"
     ]
    }
   ],
   "source": [
    "results_file = open('./results.csv', 'a')\n",
    "\n",
    "#base_model = CalibratedClassifierCV(Perceptron(random_state=0))\n",
    "base_model = Perceptron(random_state=0)\n",
    "meta_model = AdaBoostClassifier(base_estimator=base_model,\n",
    "                                algorithm='SAMME', random_state=0)           \n",
    "run_model('AdaBoost',meta_model, results_file, save_models=True)           \n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Linear Oracles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_rlo(meta_model_name, meta_model, results_file, save_models):\n",
    "    for n in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "        print('Running', meta_model_name, 'with %d base estimators'%n)\n",
    "        meta_model = RLO(base_estimator=Perceptron(random_state=0))\n",
    "        meta_model.n_estimators=n\n",
    "        #for name in ['vowel0']:\n",
    "        for name in ds_names:\n",
    "            acc_folds = []\n",
    "            f1_folds = []\n",
    "            g_mean_folds = []\n",
    "            oracle_scores = []\n",
    "            for fold in range(5):\n",
    "                ## Gather training data:\n",
    "                ds_train = datasets[name]['train'][fold]\n",
    "                target_att = ds_train.columns.tolist()[-1]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1).to_numpy()\n",
    "                y_train = ds_train[target_att].to_numpy()\n",
    "\n",
    "                ## Gather test data:\n",
    "                ds_test = datasets[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1).to_numpy()\n",
    "                y_test = ds_test[target_att].to_numpy()\n",
    "                while True:\n",
    "                    try:\n",
    "                        ## Train model with the training data:\n",
    "                        meta_model.fit(X_train,y_train)\n",
    "                        ## Test model:\n",
    "                        #y_pred = meta_model.predict(X_test)\n",
    "                        predictions, pred_ens, erro = meta_model.predict(X_test, y_test)\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "                    break\n",
    "                \n",
    "                if save_models:\n",
    "                    ## Save the model object to a file for later use\n",
    "                    filename = 'saved_models/'+meta_model_name+'_n'+str(n)+'_dataset_'+name+'_fold_'+str(fold)+'.sav'\n",
    "                    pickle.dump(meta_model, open(filename, 'wb'))\n",
    "                    ## Later load model with: loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "                y_pred = pred_ens.T.ravel()\n",
    "                ## Calculate metrics:\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "                g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "                ## Store metrics for this fold:\n",
    "                acc_folds.append(acc)\n",
    "                f1_folds.append(f1)\n",
    "                g_mean_folds.append(g_mean)\n",
    "                #cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                #print(cnf_matrix)\n",
    "\n",
    "                oracle_score = meta_model.Oracle_score(X_test, y_test)\n",
    "                oracle_scores.append(oracle_score)\n",
    "\n",
    "            ## Calculate means and std devs for each metric \n",
    "            acc_mean = str(np.average(acc_folds))\n",
    "            acc_std_dev = str(np.std(acc_folds))\n",
    "            f1_mean = str(np.average(f1_folds))\n",
    "            f1_std_dev = str(np.std(f1_folds))\n",
    "            g_mean_mean = str(np.average(g_mean_folds))\n",
    "            g_mean_std_dev = str(np.std(g_mean_folds))\n",
    "            oracle_mean = str(np.average(oracle_scores))\n",
    "            oracle_std_dev = str(np.std(oracle_scores))\n",
    "            results_file.write(name+','+meta_model_name+','+str(n)+','+acc_mean+','+acc_std_dev+','+f1_mean+','\n",
    "                               +f1_std_dev+','+g_mean_mean+','+g_mean_std_dev+','+oracle_mean+','+oracle_std_dev+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RLO with 10 base estimators\n",
      "Running RLO with 20 base estimators\n",
      "Running RLO with 30 base estimators\n",
      "Running RLO with 40 base estimators\n",
      "Running RLO with 50 base estimators\n",
      "Running RLO with 60 base estimators\n",
      "Running RLO with 70 base estimators\n",
      "Running RLO with 80 base estimators\n",
      "Running RLO with 90 base estimators\n",
      "Running RLO with 100 base estimators\n"
     ]
    }
   ],
   "source": [
    "results_file = open('./results.csv', 'a')\n",
    "\n",
    "#base_model = CalibratedClassifierCV(Perceptron(random_state=0))\n",
    "base_model = Perceptron(random_state=0)\n",
    "meta_model = RLO(base_estimator=base_model)\n",
    "\n",
    "\n",
    "run_model_rlo('RLO',meta_model, results_file, save_models=True)           \n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_rs(meta_model_name, meta_model, results_file, save_models):\n",
    "    for n in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "        print('Running', meta_model_name, 'with %d base estimators'%n)\n",
    "        meta_model.n_estimators=n\n",
    "        for name in ds_names:\n",
    "            acc_folds = []\n",
    "            f1_folds = []\n",
    "            g_mean_folds = []\n",
    "            oracle_scores = []\n",
    "            for fold in range(5):\n",
    "                ## Gather training data:\n",
    "                ds_train = datasets[name]['train'][fold]\n",
    "                target_att = ds_train.columns.tolist()[-1]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "                y_train = ds_train[target_att]\n",
    "\n",
    "                ## Gather test data:\n",
    "                ds_test = datasets[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "                y_test = ds_test[target_att]\n",
    "\n",
    "                ## Train model with the training data:\n",
    "                meta_model.fit(X_train,y_train)\n",
    "\n",
    "                if save_models:\n",
    "                    ## Save the model object to a file for later use\n",
    "                    filename = 'saved_models/'+meta_model_name+'_n'+str(n)+'_dataset_'+name+'_fold_'+str(fold)+'.sav'\n",
    "                    pickle.dump(meta_model, open(filename, 'wb'))\n",
    "                    ## Later load model with: loaded_model = pickle.load(open(filename, 'rb'))\n",
    "                    \n",
    "                ## Test model:\n",
    "                y_pred = meta_model.predict(X_test)\n",
    "                \n",
    "                ## Calculate metrics:\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "                g_mean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "                ## Store metrics for this fold:\n",
    "                acc_folds.append(acc)\n",
    "                f1_folds.append(f1)\n",
    "                g_mean_folds.append(g_mean)\n",
    "                #cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                #print(cnf_matrix)\n",
    "\n",
    "                base_models = meta_model.estimators_\n",
    "                base_models_feats = meta_model.estimators_features_\n",
    "\n",
    "                base_models_preds = []\n",
    "                for i in range(len(base_models)):\n",
    "                    #selecting only the columns used for the ith base model.\n",
    "                    X_test_subspace = X_test.iloc[:,base_models_feats[i]] \n",
    "                    y_pred = base_models[i].predict(X_test_subspace)\n",
    "                    base_models_preds.append(y_pred)\n",
    "\n",
    "                oracle_hits = []\n",
    "                for i in range(len(y_test)):\n",
    "                    oracle_hit = 0\n",
    "                    for j in range(len(base_models_preds)):\n",
    "                        if base_models_preds[j][i] == y_test[i]:\n",
    "                            oracle_hit = 1\n",
    "                            break\n",
    "                    oracle_hits.append(oracle_hit)\n",
    "\n",
    "                oracle_score = np.sum(oracle_hits)/len(oracle_hits)\n",
    "                oracle_scores.append(oracle_score)\n",
    "\n",
    "            ## Calculate means and std devs for each metric \n",
    "            acc_mean = str(np.average(acc_folds))\n",
    "            acc_std_dev = str(np.std(acc_folds))\n",
    "            f1_mean = str(np.average(f1_folds))\n",
    "            f1_std_dev = str(np.std(f1_folds))\n",
    "            g_mean_mean = str(np.average(g_mean_folds))\n",
    "            g_mean_std_dev = str(np.std(g_mean_folds))\n",
    "            oracle_mean = str(np.average(oracle_scores))\n",
    "            oracle_std_dev = str(np.std(oracle_scores))\n",
    "            results_file.write(name+','+meta_model_name+','+str(n)+','+acc_mean+','+acc_std_dev+','+f1_mean+','\n",
    "                               +f1_std_dev+','+g_mean_mean+','+g_mean_std_dev+','+oracle_mean+','+oracle_std_dev+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomSubspaces with 10 base estimators\n",
      "Running RandomSubspaces with 20 base estimators\n",
      "Running RandomSubspaces with 30 base estimators\n",
      "Running RandomSubspaces with 40 base estimators\n",
      "Running RandomSubspaces with 50 base estimators\n",
      "Running RandomSubspaces with 60 base estimators\n",
      "Running RandomSubspaces with 70 base estimators\n",
      "Running RandomSubspaces with 80 base estimators\n",
      "Running RandomSubspaces with 90 base estimators\n",
      "Running RandomSubspaces with 100 base estimators\n"
     ]
    }
   ],
   "source": [
    "results_file = open('./results.csv', 'a')\n",
    "\n",
    "#base_model = CalibratedClassifierCV(Perceptron(random_state=0))\n",
    "base_model = Perceptron(random_state=0)\n",
    "meta_model = BaggingClassifier(base_estimator=base_model, n_jobs=-1,\n",
    "                                random_state=0, bootstrap=False,\n",
    "                                bootstrap_features=False, max_features=0.5) \n",
    "#These three last parameters in the above class constructor call make it behave as the Random Subspace algoritm.\n",
    "\n",
    "run_model_rs('RandomSubspaces',meta_model, results_file, save_models=True)           \n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's load the results.csv file into a dataframe:\n",
    "results_df = pd.read_csv('results.csv', header='infer', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>model</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acc_std_dev</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std_dev</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>g_mean_std_dev</th>\n",
       "      <th>oracle_mean</th>\n",
       "      <th>oracle_std_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ecoli3</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910579</td>\n",
       "      <td>0.028528</td>\n",
       "      <td>0.525312</td>\n",
       "      <td>0.282078</td>\n",
       "      <td>0.674691</td>\n",
       "      <td>0.356176</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>segment0</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993935</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.978430</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.984899</td>\n",
       "      <td>0.014319</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>vehicle2</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935030</td>\n",
       "      <td>0.036744</td>\n",
       "      <td>0.872521</td>\n",
       "      <td>0.076002</td>\n",
       "      <td>0.913713</td>\n",
       "      <td>0.060763</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>yeast3</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923860</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.657619</td>\n",
       "      <td>0.092038</td>\n",
       "      <td>0.803888</td>\n",
       "      <td>0.089416</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>glass6</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934551</td>\n",
       "      <td>0.053874</td>\n",
       "      <td>0.758974</td>\n",
       "      <td>0.182286</td>\n",
       "      <td>0.846550</td>\n",
       "      <td>0.116719</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ecoli3</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919535</td>\n",
       "      <td>0.020479</td>\n",
       "      <td>0.562976</td>\n",
       "      <td>0.175241</td>\n",
       "      <td>0.701389</td>\n",
       "      <td>0.166062</td>\n",
       "      <td>0.9910447761194028</td>\n",
       "      <td>0.011940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>segment0</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>10</td>\n",
       "      <td>0.997399</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.992107</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.9978326806960214</td>\n",
       "      <td>0.001372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>vehicle2</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>10</td>\n",
       "      <td>0.957466</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.914590</td>\n",
       "      <td>0.028610</td>\n",
       "      <td>0.934055</td>\n",
       "      <td>0.024346</td>\n",
       "      <td>0.992906369648451</td>\n",
       "      <td>0.008697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>yeast3</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>10</td>\n",
       "      <td>0.949470</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.745954</td>\n",
       "      <td>0.081053</td>\n",
       "      <td>0.818269</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>0.9898944398944399</td>\n",
       "      <td>0.003684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>glass6</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>10</td>\n",
       "      <td>0.934551</td>\n",
       "      <td>0.022863</td>\n",
       "      <td>0.734452</td>\n",
       "      <td>0.104338</td>\n",
       "      <td>0.813531</td>\n",
       "      <td>0.079212</td>\n",
       "      <td>0.9813953488372092</td>\n",
       "      <td>0.022786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>ecoli3</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>20</td>\n",
       "      <td>0.928534</td>\n",
       "      <td>0.025762</td>\n",
       "      <td>0.600256</td>\n",
       "      <td>0.207759</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>0.184389</td>\n",
       "      <td>0.9910447761194028</td>\n",
       "      <td>0.011940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>segment0</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>20</td>\n",
       "      <td>0.997399</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.992107</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.9982655811289216</td>\n",
       "      <td>0.001623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset Name       model  n_estimators  accuracy  acc_std_dev        f1  \\\n",
       "0        ecoli3  Perceptron             1  0.910579     0.028528  0.525312   \n",
       "1      segment0  Perceptron             1  0.993935     0.003183  0.978430   \n",
       "2      vehicle2  Perceptron             1  0.935030     0.036744  0.872521   \n",
       "3        yeast3  Perceptron             1  0.923860     0.015122  0.657619   \n",
       "4        glass6  Perceptron             1  0.934551     0.053874  0.758974   \n",
       "5        ecoli3     Bagging            10  0.919535     0.020479  0.562976   \n",
       "6      segment0     Bagging            10  0.997399     0.002126  0.990769   \n",
       "7      vehicle2     Bagging            10  0.957466     0.013615  0.914590   \n",
       "8        yeast3     Bagging            10  0.949470     0.013940  0.745954   \n",
       "9        glass6     Bagging            10  0.934551     0.022863  0.734452   \n",
       "10       ecoli3     Bagging            20  0.928534     0.025762  0.600256   \n",
       "11     segment0     Bagging            20  0.997399     0.002126  0.990769   \n",
       "\n",
       "    f1_std_dev    g_mean  g_mean_std_dev         oracle_mean  oracle_std_dev  \n",
       "0     0.282078  0.674691        0.356176                                 NaN  \n",
       "1     0.011671  0.984899        0.014319                                 NaN  \n",
       "2     0.076002  0.913713        0.060763                                 NaN  \n",
       "3     0.092038  0.803888        0.089416                                 NaN  \n",
       "4     0.182286  0.846550        0.116719                                 NaN  \n",
       "5     0.175241  0.701389        0.166062  0.9910447761194028        0.011940  \n",
       "6     0.007610  0.992107        0.008178  0.9978326806960214        0.001372  \n",
       "7     0.028610  0.934055        0.024346   0.992906369648451        0.008697  \n",
       "8     0.081053  0.818269        0.064084  0.9898944398944399        0.003684  \n",
       "9     0.104338  0.813531        0.079212  0.9813953488372092        0.022786  \n",
       "10    0.207759  0.721000        0.184389  0.9910447761194028        0.011940  \n",
       "11    0.007610  0.992107        0.008178  0.9982655811289216        0.001623  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_results_q1_file =  open('./acc_results_q1.csv', 'a')\n",
    "header = 'dataset,n_estimators,Bagging,Bag_std,AdaBoost,Ada_std,RandomSubspaces,RS_std,RLO,RLO_std\\n'\n",
    "acc_results_q1_file.write(header)\n",
    "for name in ds_names:\n",
    "    df_filt_name = results_df[results_df['Dataset Name'] == name]\n",
    "    for n in range(10,110,10):\n",
    "        df_filt_n = df_filt_name[df_filt_name['n_estimators'] == n]\n",
    "        acc_Bag = df_filt_n[df_filt_n['model'] == 'Bagging']['accuracy'].values[0]\n",
    "        acc_Bag_std = df_filt_n[df_filt_n['model'] == 'Bagging']['acc_std_dev'].values[0]\n",
    "        acc_Ada = df_filt_n[df_filt_n['model'] == 'AdaBoost']['accuracy'].values[0]\n",
    "        acc_Ada_std = df_filt_n[df_filt_n['model'] == 'AdaBoost']['acc_std_dev'].values[0]\n",
    "        acc_RS = df_filt_n[df_filt_n['model'] == 'RandomSubspaces']['accuracy'].values[0]\n",
    "        acc_RS_std = df_filt_n[df_filt_n['model'] == 'RandomSubspaces']['acc_std_dev'].values[0]\n",
    "        acc_RLO = df_filt_n[df_filt_n['model'] == 'RLO']['accuracy'].values[0]\n",
    "        acc_RLO_std = df_filt_n[df_filt_n['model'] == 'RLO']['acc_std_dev'].values[0]\n",
    "        csv_line = name+','+str(n)+','+str(acc_Bag)+','+str(acc_Bag_std)+','+str(acc_Ada)+','+str(acc_Ada_std)\\\n",
    "        +','+str(acc_RS)+','+str(acc_RS_std)+','+str(acc_RLO)+','+str(acc_RLO_std)+'\\n'\n",
    "        acc_results_q1_file.write(csv_line)\n",
    "            \n",
    "acc_results_q1_file.close()\n",
    "acc_results_df = pd.read_csv('acc_results_q1.csv', encoding='utf8', engine='python', sep=',', header=0)\n",
    "#acc_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_results_q1_file =  open('./f1_results_q1.csv', 'a')\n",
    "header = 'dataset,n_estimators,Bagging,Bag_std,AdaBoost,Ada_std,RandomSubspaces,RS_std,RLO,RLO_std\\n'\n",
    "f1_results_q1_file.write(header)\n",
    "for name in ds_names:\n",
    "    df_filt_name = results_df[results_df['Dataset Name'] == name]\n",
    "    for n in range(10,110,10):\n",
    "        df_filt_n = df_filt_name[df_filt_name['n_estimators'] == n]\n",
    "        f1_Bag = df_filt_n[df_filt_n['model'] == 'Bagging']['f1'].values[0]\n",
    "        f1_Bag_std = df_filt_n[df_filt_n['model'] == 'Bagging']['f1_std_dev'].values[0]\n",
    "        f1_Ada = df_filt_n[df_filt_n['model'] == 'AdaBoost']['f1'].values[0]\n",
    "        f1_Ada_std = df_filt_n[df_filt_n['model'] == 'AdaBoost']['f1_std_dev'].values[0]\n",
    "        f1_RS = df_filt_n[df_filt_n['model'] == 'RandomSubspaces']['f1'].values[0]\n",
    "        f1_RS_std = df_filt_n[df_filt_n['model'] == 'RandomSubspaces']['f1_std_dev'].values[0]\n",
    "        f1_RLO = df_filt_n[df_filt_n['model'] == 'RLO']['f1'].values[0]\n",
    "        f1_RLO_std = df_filt_n[df_filt_n['model'] == 'RLO']['f1_std_dev'].values[0]\n",
    "        csv_line = name+','+str(n)+','+str(f1_Bag)+','+str(f1_Bag_std)+','+str(f1_Ada)+','+str(f1_Ada_std)\\\n",
    "        +','+str(f1_RS)+','+str(f1_RS_std)+','+str(f1_RLO)+','+str(f1_RLO_std)+'\\n'\n",
    "        f1_results_q1_file.write(csv_line)\n",
    "            \n",
    "f1_results_q1_file.close()\n",
    "f1_results_df = pd.read_csv('f1_results_q1.csv', encoding='utf8', engine='python', sep=',', header=0)\n",
    "#f1_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ora_results_q1_file =  open('./ora_results_q1.csv', 'a')\n",
    "header = 'dataset,n_estimators,Bagging,Bag_std,AdaBoost,Ada_std,RandomSubspaces,RS_std,RLO,RLO_std\\n'\n",
    "ora_results_q1_file.write(header)\n",
    "for name in ds_names:\n",
    "    df_filt_name = results_df[results_df['Dataset Name'] == name]\n",
    "    for n in range(10,110,10):\n",
    "        df_filt_n = df_filt_name[df_filt_name['n_estimators'] == n]\n",
    "        ora_Bag = df_filt_n[df_filt_n['model'] == 'Bagging']['oracle_mean'].values[0]\n",
    "        ora_Bag_std = df_filt_n[df_filt_n['model'] == 'Bagging']['oracle_std_dev'].values[0]\n",
    "        ora_Ada = df_filt_n[df_filt_n['model'] == 'AdaBoost']['oracle_mean'].values[0]\n",
    "        ora_Ada_std = df_filt_n[df_filt_n['model'] == 'AdaBoost']['oracle_std_dev'].values[0]\n",
    "        ora_RS = df_filt_n[df_filt_n['model'] == 'RandomSubspaces']['oracle_mean'].values[0]\n",
    "        ora_RS_std = df_filt_n[df_filt_n['model'] == 'RandomSubspaces']['oracle_std_dev'].values[0]\n",
    "        ora_RLO = df_filt_n[df_filt_n['model'] == 'RLO']['oracle_mean'].values[0]\n",
    "        ora_RLO_std = df_filt_n[df_filt_n['model'] == 'RLO']['oracle_std_dev'].values[0]\n",
    "        csv_line = name+','+str(n)+','+str(ora_Bag)+','+str(ora_Bag_std)+','+str(ora_Ada)+','+str(ora_Ada_std)\\\n",
    "        +','+str(ora_RS)+','+str(ora_RS_std)+','+str(ora_RLO)+','+str(ora_RLO_std)+'\\n'\n",
    "        ora_results_q1_file.write(csv_line)\n",
    "            \n",
    "ora_results_q1_file.close()\n",
    "ora_results_df = pd.read_csv('ora_results_q1.csv', encoding='utf8', engine='python', sep=',', header=0)\n",
    "#ora_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ora_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ds_names:\n",
    "    df_acc = acc_results_df[acc_results_df['dataset']==name]\n",
    "    df_f1  = f1_results_df[f1_results_df['dataset']==name]\n",
    "    df_ora = ora_results_df[ora_results_df['dataset']==name]\n",
    "    \n",
    "    x = df_acc.n_estimators\n",
    "    \n",
    "    y1acc = df_acc.Bagging\n",
    "    y2acc = df_acc.AdaBoost\n",
    "    y3acc = df_acc.RandomSubspaces\n",
    "    y4acc = df_acc.RLO\n",
    "    \n",
    "    y1f1 = df_f1.Bagging\n",
    "    y2f1 = df_f1.AdaBoost\n",
    "    y3f1 = df_f1.RandomSubspaces\n",
    "    y4f1 = df_f1.RLO\n",
    "    \n",
    "    y1ora = df_ora.Bagging\n",
    "    y2ora = df_ora.AdaBoost\n",
    "    y3ora = df_ora.RandomSubspaces\n",
    "    y4ora = df_ora.RLO\n",
    "    \n",
    "    plt.plot(x,y1acc,'b-', label='Bagging')\n",
    "    plt.plot(x,y2acc,'r-', label='Adaboost')\n",
    "    plt.plot(x,y3acc,'g-', label='Random Subspaces')\n",
    "    plt.plot(x,y4acc,'c-', label='RLO')\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Mean accuracy for dataset '+name)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('number of base classifiers')\n",
    "    plt.ylim((0.6, 1.0))\n",
    "    #plt.show()\n",
    "    plt.savefig(fname='./figs/mean_acc_'+name+'.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(x,y1f1,'b-', label='Bagging')\n",
    "    plt.plot(x,y2f1,'r-', label='Adaboost')\n",
    "    plt.plot(x,y3f1,'g-', label='Random Subspaces')\n",
    "    plt.plot(x,y4f1,'c-', label='RLO')\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Mean F1-measure for dataset '+name)\n",
    "    plt.ylabel('F1-measure (test dataset)')\n",
    "    plt.xlabel('number of base classifiers')\n",
    "    plt.ylim((0.1, 1.0))\n",
    "    #plt.show()\n",
    "    plt.savefig(fname='./figs/mean_f1_'+name+'.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(x,y1ora,'b-', label='Bagging')\n",
    "    plt.plot(x,y2ora,'r-', label='Adaboost')\n",
    "    plt.plot(x,y3ora,'g-', label='Random Subspaces')\n",
    "    plt.plot(x,y4ora,'c-', label='RLO')\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Mean oracle accuracy for dataset '+name)\n",
    "    plt.ylabel('oracle accuracy (test dataset)')\n",
    "    plt.xlabel('number of base classifiers')\n",
    "    plt.ylim((0.5, 1.0))\n",
    "    #plt.show()\n",
    "    plt.savefig(fname='./figs/mean_oracle_'+name+'.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve visualization of the oracle accuracy graphs, let's remove the RLO model and change scales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ds_names:\n",
    "    df_acc = acc_results_df[acc_results_df['dataset']==name]\n",
    "    df_f1  = f1_results_df[f1_results_df['dataset']==name]\n",
    "    df_ora = ora_results_df[ora_results_df['dataset']==name]\n",
    "    \n",
    "    x = df_acc.n_estimators\n",
    "    \n",
    "    y1acc = df_acc.Bagging\n",
    "    y2acc = df_acc.AdaBoost\n",
    "    y3acc = df_acc.RandomSubspaces\n",
    "    #y4acc = df_acc.RLO\n",
    "    \n",
    "    y1f1 = df_f1.Bagging\n",
    "    y2f1 = df_f1.AdaBoost\n",
    "    y3f1 = df_f1.RandomSubspaces\n",
    "    #y4f1 = df_f1.RLO\n",
    "    \n",
    "    y1ora = df_ora.Bagging\n",
    "    y2ora = df_ora.AdaBoost\n",
    "    y3ora = df_ora.RandomSubspaces\n",
    "    #y4ora = df_ora.RLO\n",
    "    \n",
    "    plt.plot(x,y1acc,'b-', label='Bagging')\n",
    "    plt.plot(x,y2acc,'r-', label='Adaboost')\n",
    "    plt.plot(x,y3acc,'g-', label='Random Subspaces')\n",
    "    #plt.plot(x,y4acc,'c-', label='RLO')\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Mean accuracy for dataset '+name)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('number of base classifiers')\n",
    "    plt.ylim((0.7, 1.0))\n",
    "    #plt.show()\n",
    "    plt.savefig(fname='./figs/mean_acc_'+name+'no_RLO.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(x,y1f1,'b-', label='Bagging')\n",
    "    plt.plot(x,y2f1,'r-', label='Adaboost')\n",
    "    plt.plot(x,y3f1,'g-', label='Random Subspaces')\n",
    "    #plt.plot(x,y4f1,'c-', label='RLO')\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Mean F1-measure for dataset '+name)\n",
    "    plt.ylabel('F1-measure (test dataset)')\n",
    "    plt.xlabel('number of base classifiers')\n",
    "    plt.ylim((0.1, 1.0))\n",
    "    #plt.show()\n",
    "    plt.savefig(fname='./figs/mean_f1_'+name+'no_RLO.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(x,y1ora,'b-', label='Bagging')\n",
    "    plt.plot(x,y2ora,'r-', label='Adaboost')\n",
    "    plt.plot(x,y3ora,'g-', label='Random Subspaces')\n",
    "    #plt.plot(x,y4ora,'c-', label='RLO')\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Mean oracle accuracy for dataset '+name)\n",
    "    plt.ylabel('oracle accuracy (test dataset)')\n",
    "    plt.xlabel('number of base classifiers')\n",
    "    plt.ylim((0.9, 1.01))\n",
    "    #plt.show()\n",
    "    plt.savefig(fname='./figs/mean_oracle_'+name+'no_RLO.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2\n",
    "\n",
    "Use as mesmas bases de dados e os mesmos folds da questão anterior e, para cada base: \n",
    "    a. use o SGH para gerar o pool de classificadores no conjunto de treinamento\n",
    "    b. calcule o Oracle do pool no conjunto de teste;\n",
    "    c. verifique quantas instâncias por classe foram incorretamente classificadas; \n",
    "    d. verifique quantos hiperplanos por classe foram gerados. Analise os resultados coletados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = open('./results_q2.csv', 'a')\n",
    "header = 'Dataset Name,model,accuracy,acc_std_dev,f1,f1_std_dev,g_mean,g_mean_std_dev,oracle,oracle_std_dev,n_hyper_mean,n_hyper_std_dev,mis_0_mean,mis_0_std_dev,mis_1_mean,mis_1_std_dev\\n'\n",
    "results_file.write(header)\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_sgh(meta_model_name, results_file, save_models):\n",
    "    print('Running', meta_model_name)\n",
    "    for name in ds_names:\n",
    "        meta_model = sgh.SGH()\n",
    "        print(name)\n",
    "        acc_folds = []\n",
    "        f1_folds = []\n",
    "        g_mean_folds = []\n",
    "        oracle_scores = []\n",
    "        mis_0_folds = []\n",
    "        mis_1_folds = []\n",
    "        n_hyper = [] # This will store the number of hyperplanes for each fold.\n",
    "        for fold in range(5):\n",
    "            ## Gather training data:\n",
    "            ds_train = datasets[name]['train'][fold]\n",
    "            target_att = ds_train.columns.tolist()[-1]\n",
    "            X_train = ds_train.drop(labels=target_att, axis = 1).to_numpy()\n",
    "            y_train = ds_train[target_att].to_numpy()\n",
    "\n",
    "            ## Gather test data:\n",
    "            ds_test = datasets[name]['test'][fold]\n",
    "            X_test = ds_test.drop(labels=target_att, axis = 1).to_numpy()\n",
    "            y_test = ds_test[target_att].to_numpy()\n",
    "            \n",
    "            ## Train model with the training data:\n",
    "            meta_model.fit(X_train,y_train)\n",
    "            \n",
    "            ## Test model\n",
    "            y_pred = meta_model.predict(X_test)\n",
    "            \n",
    "            if save_models:\n",
    "                ## Save the model object to a file for later use\n",
    "                filename = 'saved_models_q2/'+meta_model_name+'_n'+str(n)+'_dataset_'+name+'_fold_'+str(fold)+'.sav'\n",
    "                pickle.dump(meta_model, open(filename, 'wb'))\n",
    "                ## Later load model with: loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "            ## Calculate metrics:\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "            g_mean = geometric_mean_score(y_test, y_pred)\n",
    "            orcl = oracle.Oracle(meta_model)\n",
    "            oracle_score = orcl.score(X_test, y_test)\n",
    "            \n",
    "            ## Count misclassified instances for each class:\n",
    "            mis = pd.Series(y_test[y_pred != y_test]).value_counts()\n",
    "            \n",
    "            ## Store metrics for this fold:\n",
    "            acc_folds.append(acc)\n",
    "            f1_folds.append(f1)\n",
    "            g_mean_folds.append(g_mean)\n",
    "            oracle_scores.append(oracle_score)\n",
    "            n_hyper.append(meta_model.n_estimators)\n",
    "            #WARNING: this is specific to binary classes:\n",
    "            #mis_0_folds.append(mis[0])\n",
    "            #mis_1_folds.append(mis[1])\n",
    "            \n",
    "        ## Calculate means and std devs for each metric \n",
    "        acc_mean = str(np.average(acc_folds))\n",
    "        acc_std_dev = str(np.std(acc_folds))\n",
    "        f1_mean = str(np.average(f1_folds))\n",
    "        f1_std_dev = str(np.std(f1_folds))\n",
    "        g_mean_mean = str(np.average(g_mean_folds))\n",
    "        g_mean_std_dev = str(np.std(g_mean_folds))\n",
    "        oracle_mean = str(np.average(oracle_scores))\n",
    "        oracle_std_dev = str(np.std(oracle_scores))\n",
    "        n_hyper_mean = str(np.average(n_hyper))\n",
    "        n_hyper_std_dev = str(np.std(n_hyper))\n",
    "        mis_0_mean = str(np.average(mis_0_folds))\n",
    "        mis_0_std_dev = str(np.std(mis_0_folds))\n",
    "        mis_1_mean = str(np.average(mis_1_folds))\n",
    "        mis_1_std_dev = str(np.std(mis_1_folds))\n",
    "        results_file.write(name+','+meta_model_name+','+acc_mean+','+acc_std_dev+','+f1_mean+','+f1_std_dev\n",
    "                           +','+g_mean_mean+','+g_mean_std_dev+','+oracle_mean+','+oracle_std_dev\n",
    "                           +','+n_hyper_mean+','+n_hyper_std_dev+','+mis_0_mean+','+mis_0_std_dev+','+mis_1_mean+','+mis_1_std_dev+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SGH\n",
      "ecoli3\n",
      "segment0\n",
      "vehicle2\n",
      "yeast3\n",
      "glass6\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') #too many warnings regarding non convergence inside the Perceptron.fit() method.\n",
    "results_file = open('./results_q2.csv', 'a')\n",
    "run_model_sgh('SGH', results_file, save_models=False)\n",
    "warnings.filterwarnings('default')\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Test SGH\n",
    "\n",
    "# meta_model = sgh.SGH()\n",
    "\n",
    "# ds_name = 'glass1'\n",
    "# ds_train = datasets[ds_name]['train'][2]  #syntax: datasets[dataset name][train or test][fold number]\n",
    "# target_att = ds_train.columns.tolist()[-1]\n",
    "# X_train = ds_train.drop(labels=target_att, axis = 1).to_numpy()\n",
    "# y_train = ds_train[target_att].to_numpy()\n",
    "# ds_test = datasets[ds_name]['test'][2]\n",
    "# X_test = ds_test.drop(labels=target_att, axis = 1).to_numpy()\n",
    "# y_test = ds_test[target_att].to_numpy()\n",
    "\n",
    "# meta_model.fit(X_train, y_train)\n",
    "# y_pred = meta_model.predict(X_test)\n",
    "\n",
    "# print('ensemble acc = ', accuracy_score(y_test, y_pred))\n",
    "# print('ensemble f1_score = ', f1_score(y_test, y_pred, pos_label=1))\n",
    "# print('ensemble g_mean = ', geometric_mean_score(y_test, y_pred))\n",
    "\n",
    "# oracle_sgh = oracle.Oracle(meta_model)\n",
    "# oracle_score = oracle_sgh.score(X_test, y_test)\n",
    "\n",
    "# print('dataset,model,oracle_score,hyperplanes')\n",
    "# print(ds_name+',SGH,'+str(oracle_score)+','+str(meta_model.n_estimators))\n",
    "\n",
    "# mis = pd.Series(y_test[y_pred != y_test]).value_counts()\n",
    "# print('misclassified instances:', mis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q2_df = pd.read_csv('results_q2.csv', encoding='utf8', engine='python', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acc_std_dev</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std_dev</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>g_mean_std_dev</th>\n",
       "      <th>oracle</th>\n",
       "      <th>oracle_std_dev</th>\n",
       "      <th>n_hyper_mean</th>\n",
       "      <th>n_hyper_std_dev</th>\n",
       "      <th>mis_0_mean</th>\n",
       "      <th>mis_0_std_dev</th>\n",
       "      <th>mis_1_mean</th>\n",
       "      <th>mis_1_std_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ecoli3</td>\n",
       "      <td>SGH</td>\n",
       "      <td>0.922695</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.554987</td>\n",
       "      <td>0.287700</td>\n",
       "      <td>0.685646</td>\n",
       "      <td>0.351032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>segment0</td>\n",
       "      <td>SGH</td>\n",
       "      <td>0.478779</td>\n",
       "      <td>0.024739</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>0.465193</td>\n",
       "      <td>0.039887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>vehicle2</td>\n",
       "      <td>SGH</td>\n",
       "      <td>0.600404</td>\n",
       "      <td>0.044896</td>\n",
       "      <td>0.354334</td>\n",
       "      <td>0.073827</td>\n",
       "      <td>0.523708</td>\n",
       "      <td>0.066071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>yeast3</td>\n",
       "      <td>SGH</td>\n",
       "      <td>0.353021</td>\n",
       "      <td>0.122758</td>\n",
       "      <td>0.146096</td>\n",
       "      <td>0.030309</td>\n",
       "      <td>0.389388</td>\n",
       "      <td>0.057415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.979796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>glass6</td>\n",
       "      <td>SGH</td>\n",
       "      <td>0.289369</td>\n",
       "      <td>0.264295</td>\n",
       "      <td>0.096545</td>\n",
       "      <td>0.057843</td>\n",
       "      <td>0.172364</td>\n",
       "      <td>0.094071</td>\n",
       "      <td>0.986047</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset Name model  accuracy  acc_std_dev        f1  f1_std_dev    g_mean  \\\n",
       "0       ecoli3   SGH  0.922695     0.019389  0.554987    0.287700  0.685646   \n",
       "1     segment0   SGH  0.478779     0.024739  0.197462    0.028308  0.465193   \n",
       "2     vehicle2   SGH  0.600404     0.044896  0.354334    0.073827  0.523708   \n",
       "3       yeast3   SGH  0.353021     0.122758  0.146096    0.030309  0.389388   \n",
       "4       glass6   SGH  0.289369     0.264295  0.096545    0.057843  0.172364   \n",
       "\n",
       "   g_mean_std_dev    oracle  oracle_std_dev  n_hyper_mean  n_hyper_std_dev  \\\n",
       "0        0.351032  1.000000        0.000000           2.0         0.000000   \n",
       "1        0.039887  1.000000        0.000000           3.6         0.489898   \n",
       "2        0.066071  1.000000        0.000000           4.0         0.000000   \n",
       "3        0.057415  1.000000        0.000000           5.2         0.979796   \n",
       "4        0.094071  0.986047        0.027907           3.6         0.800000   \n",
       "\n",
       "   mis_0_mean  mis_0_std_dev  mis_1_mean  mis_1_std_dev  \n",
       "0         NaN            NaN         NaN            NaN  \n",
       "1         NaN            NaN         NaN            NaN  \n",
       "2         NaN            NaN         NaN            NaN  \n",
       "3         NaN            NaN         NaN            NaN  \n",
       "4         NaN            NaN         NaN            NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_q2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",Dataset Name,model,accuracy,acc_std_dev,f1,f1_std_dev,g_mean,g_mean_std_dev,oracle,oracle_std_dev,n_hyper_mean,n_hyper_std_dev,mis_0_mean,mis_0_std_dev,mis_1_mean,mis_1_std_dev\n",
      "0,ecoli3,SGH,\"0,9226953467954344\",\"0,01938907569564151\",\"0,5549874686716791\",\"0,28769980634856\",\"0,6856457932500117\",\"0,35103159335292805\",\"1,0\",\"0,0\",\"2,0\",\"0,0\",,,,\n",
      "1,segment0,SGH,\"0,4787794273694491\",\"0,024738739110136788\",\"0,1974619803415083\",\"0,028307929211467006\",\"0,4651931270951497\",\"0,03988748432631765\",\"1,0\",\"0,0\",\"3,6\",\"0,4898979485566356\",,,,\n",
      "2,vehicle2,SGH,\"0,6004037591367909\",\"0,04489589819358954\",\"0,3543342001358004\",\"0,07382718504420062\",\"0,5237080847805191\",\"0,06607092111933145\",\"1,0\",\"0,0\",\"4,0\",\"0,0\",,,,\n",
      "3,yeast3,SGH,\"0,35302120302120293\",\"0,1227584242353101\",\"0,14609641082855016\",\"0,030308513898729045\",\"0,3893881072234013\",\"0,05741488558359286\",\"1,0\",\"0,0\",\"5,2\",\"0,9797958971132712\",,,,\n",
      "4,glass6,SGH,\"0,2893687707641196\",\"0,264294849818406\",\"0,09654507215482824\",\"0,057842714732257786\",\"0,17236359722112932\",\"0,09407097805142067\",\"0,9860465116279068\",\"0,02790697674418605\",\"3,6\",\"0,8000000000000002\",,,,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_q2_df.to_csv(decimal=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92269535, 0.47877943, 0.60040376, 0.3530212 , 0.28936877])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_q2_df.accuracy.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting accuracies as a grouped barplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = results_q2_df.accuracy.values\n",
    "bars2 = results_q2_df.oracle.values\n",
    "\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='#C29CA3', width=barWidth, edgecolor='white', label='accuracy')\n",
    "plt.bar(r2, bars2, color='#CDCDCD', width=barWidth, edgecolor='white', label='oracle')\n",
    "\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('dataset', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ['wisconsin', 'pima', 'yeast1', 'ecoli2', 'abalone'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend(loc='center right')\n",
    "plt.show()\n",
    "#plt.savefig(fname='./figs/q2_accuracies.png', dpi=300)\n",
    "plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[336, 2308, 846, 1484, 214]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the number of instances for each dataset:\n",
    "sizes = []\n",
    "for k in datasets:\n",
    "    n = datasets[k]['train'][0].shape[0] + datasets[k]['test'][0].shape[0]\n",
    "    sizes.append(n)\n",
    "\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_q2_df.mis_0_mean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_q2_df.mis_0_mean.values/sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting percentage of misclassified examples per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = results_q2_df.n_hyper_mean.values\n",
    "bars2 = results_q2_df.mis_0_mean.values/sizes\n",
    "bars3 = results_q2_df.mis_1_mean.values/sizes\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    " \n",
    "# Make the plot\n",
    "#plt.bar(r1, bars1, color='#C29CA3', width=barWidth, edgecolor='white', label='hyperplanes')\n",
    "plt.bar(r2, bars2, color='#CDCDCD', width=barWidth, edgecolor='white', label='misclassified - class 0')\n",
    "plt.bar(r3, bars3, color='#C29CA3', width=barWidth, edgecolor='white', label='misclassified - class 1')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('dataset', fontweight='bold')\n",
    "plt.ylabel('Percentage of misclassified instances')\n",
    "plt.xticks([r + 1.5*barWidth for r in range(len(bars1))], ['wisconsin', 'pima', 'yeast1', 'ecoli2', 'abalone'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend(loc='center right')\n",
    "plt.show()\n",
    "#plt.savefig(fname='./figs/q2_misclassified.png', dpi=300)\n",
    "plt.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting number of hyperplanes used by SGH for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.35\n",
    " \n",
    "# set height of bar\n",
    "bars1 = results_q2_df.n_hyper_mean.values\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='grey', width=barWidth, edgecolor='white', label='hyperplanes')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('dataset', fontweight='bold')\n",
    "plt.ylabel('Number of hyperplanes')\n",
    "plt.xticks([r for r in range(len(bars1))], ['wisconsin', 'pima', 'yeast1', 'ecoli2', 'abalone'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "#plt.legend(loc='center right')\n",
    "plt.show()\n",
    "#plt.savefig(fname='./figs/q2_hyperplanes.png', dpi=300)\n",
    "plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
